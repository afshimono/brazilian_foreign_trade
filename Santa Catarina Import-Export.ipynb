{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and Export Data for Santa Catarina\n",
    "\n",
    "We want to answer the folowing questions:\n",
    "\n",
    "* What are the top 3 most exported products by State for the years 2017, 2018 and 2019?\n",
    "* What are the top 3 most imported products by State for the years 2017, 2018 and 2019?\n",
    "* What are the top 3 most exported products in each month of 2019 by State?\n",
    "* What is the percentage of total national exports by State in 2019?\n",
    "* What is the percentage of total national imports by State in 2019?\n",
    "* Prediction of value of top 3 exported products by month from Santa Catarina to each target Country.\n",
    "* Prediction of value of top 3 imported products by month from Santa Catarina from each source Country.\n",
    "\n",
    "## Contents\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Part 1: Data Wrangling for Exports\n",
    "\n",
    "First step to address our analysis will be to download the files, unzip them, clean them and finally organize the best way possible. I have decided to store the link to the government website and download it as we execute the notebook instead of uploading the file as Git LFS because those file locations **should not** change at all. Considering we are betting on the Brazilian government efficiency, we will store the MD5 of the used files \"just in case\" they ever change for any reason. One faster way to do this is simply download the zip files yourself and put them in the data folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import requests\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os\n",
    "import asyncio\n",
    "import hashlib\n",
    "import base64\n",
    "import zipfile\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "EXP_MD5 = b'qQlAf4t9CVrpQ9h+fMMqfw=='\n",
    "IMP_MD5 = b'X5m1GyzT+AlRGNciPVHrOA=='"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download files (have patience young padawan...)\n",
    "async def download_to_data_folder(file_url:str)->str:\n",
    "    local_filename = 'data/'+file_url.split('/')[-1]\n",
    "    with requests.get(file_url, stream=True) as r:\n",
    "        r.raise_for_status()\n",
    "        with open(local_filename, 'wb') as f:\n",
    "            downloaded = 0\n",
    "            for chunk in r.iter_content(chunk_size=32768): \n",
    "                if chunk: # filter out keep-alive new chunks\n",
    "                    f.write(chunk)\n",
    "                    downloaded += 32768\n",
    "                    print(file_url.split('/')[-1]+'  '+str(downloaded),end='\\r')\n",
    "    return local_filename\n",
    "\n",
    "async def download_all_files()->list:\n",
    "    request_list = []\n",
    "    request_list.append(download_to_data_folder('http://www.mdic.gov.br/balanca/bd/comexstat-bd/ncm/EXP_COMPLETA.zip'))\n",
    "    request_list.append(download_to_data_folder('http://www.mdic.gov.br/balanca/bd/comexstat-bd/ncm/IMP_COMPLETA.zip'))\n",
    "    return asyncio.gather(*request_list)\n",
    "\n",
    "if not os.path.exists('data/EXP_COMPLETA.zip'):\n",
    "    file_list = await download_all_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check MD5\n",
    "for file in os.listdir('data/'):\n",
    "    if file == 'EXP_COMPLETA.zip' or file == 'IMP_COMPLETA.zip':\n",
    "        file_hash = hashlib.md5()\n",
    "        with open('data/'+file,'rb') as f:\n",
    "            for chunk in iter(lambda: f.read(2**20*file_hash.block_size), b''):\n",
    "                file_hash.update(chunk)\n",
    "        if base64.b64encode(file_hash.digest()) != EXP_MD5 and base64.b64encode(file_hash.digest()) != IMP_MD5:\n",
    "            print(EXP_MD5)\n",
    "            print(IMP_MD5)\n",
    "            print(base64.b64encode(file_hash.digest()))\n",
    "            raise Exception('Wrong file downloaded!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXP_COMPLETA.csv\n",
      "EXP_COMPLETA.zip\n",
      "IMP_COMPLETA.csv\n",
      "IMP_COMPLETA.zip\n",
      "NCM.csv\n",
      "PAIS.csv\n",
      "README.txt\n",
      "URF.csv\n",
      "VIA.csv\n"
     ]
    }
   ],
   "source": [
    "#unzip files\n",
    "for file in os.listdir('data/'):\n",
    "    print(file)\n",
    "    if file[-3:] == 'zip':\n",
    "        if not os.path.exists('data/'+file[:-3]+'csv'):\n",
    "            with zipfile.ZipFile('data/'+file,\"r\") as zip_ref:\n",
    "                zip_ref.extractall(\"data/\")\n",
    "                print('Extracted '+file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with exports. One important point we notice are the file sizes. One has around 1.5G unzipped, the other has 2.15G. Those may be a problem for python if you are using a computer with less than 8G RAM Memory.\n",
    "\n",
    "LetÂ´s import the first one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_df = pd.read_csv('data/EXP_COMPLETA.csv', delimiter=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will replace the names with more human friendly ones, and we notice that some of the data is using codes like integers, not in a human friendly naming system. Those will have to be addressed as well. Reading the documentation in http://www.mdic.gov.br/index.php/comercio-exterior/estatisticas-de-comercio-exterior/base-de-dados-do-comercio-exterior-brasileiro-arquivos-para-download , we can download the missing tables and change our data to a more friendly one.\n",
    "\n",
    "First thing I learned was what FOB means! https://www.ipea.gov.br/desafios/index.php?option=com_content&view=article&id=2115:catid=28&Itemid=23\n",
    "\n",
    "So, the column VL_FOB should be renamed to Amount(USD). We also need to download the remaining tables with more human friendly definitions so we get our final Dataframe. Another impotant aspect to notice is that we will only need data from 2017 - 2019, so we will filter those in order to spare some memory space.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtering years\n",
    "exp_df.query('CO_ANO in [2017,2018,2019]', inplace=True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Renaming\n",
    "exp_df.rename(\n",
    "    columns={\n",
    "        \"CO_ANO\":\"Ano\",\n",
    "        \"VL_FOB\":\"Amount(USD)\",\n",
    "        \"KG_LIQUIDO\":\"Kg\",\n",
    "        \"SG_UF_NCM\":\"Estado\",\n",
    "        \"CO_MES\":\"Mes\"\n",
    "    },inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def download_missing_tables():\n",
    "    request_list = []\n",
    "    if not os.path.exists('data/PAIS.csv'):\n",
    "        request_list.append(download_to_data_folder('http://www.mdic.gov.br/balanca/bd/tabelas/PAIS.csv'))\n",
    "    if not os.path.exists('data/VIA.csv'):\n",
    "        request_list.append(download_to_data_folder('http://www.mdic.gov.br/balanca/bd/tabelas/VIA.csv'))\n",
    "    if not os.path.exists('data/NCM.csv'):\n",
    "        request_list.append(download_to_data_folder('http://www.mdic.gov.br/balanca/bd/tabelas/NCM.csv'))\n",
    "    if len(request_list)>0:\n",
    "        return asyncio.gather(*request_list)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "await download_missing_tables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pais_df = pd.read_csv('data/PAIS.csv', delimiter=';', encoding=\"latin-1\")\n",
    "via_df = pd.read_csv('data/VIA.csv', delimiter=';', encoding=\"latin-1\")\n",
    "produto_df = pd.read_csv('data/NCM.csv', delimiter=';', encoding=\"latin-1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_df = exp_df.merge(pais_df,how='inner',on='CO_PAIS')\n",
    "exp_df.drop(['CO_PAIS','QT_ESTAT','CO_PAIS_ISON3','NO_PAIS_ING','CO_PAIS_ISOA3','NO_PAIS_ESP'],axis=1,inplace=True)\n",
    "exp_df = exp_df.merge(via_df,how='inner',on='CO_VIA')\n",
    "exp_df = exp_df.merge(produto_df,how='inner',on=['CO_NCM','CO_UNID'])\n",
    "exp_df.drop([\n",
    "    'CO_NCM',\n",
    "    'CO_UNID',\n",
    "    'CO_VIA',\n",
    "    'CO_URF',\n",
    "    'CO_PPI',\n",
    "    'CO_FAT_AGREG',\n",
    "    'CO_CUCI_ITEM',\n",
    "    'CO_CGCE_N3',\n",
    "    'CO_SIIT',\n",
    "    'CO_ISIC4',\n",
    "    'CO_EXP_SUBSET',\n",
    "    'NO_NCM_ESP',\n",
    "    'NO_NCM_ING',\n",
    "    'CO_SH6',\n",
    "    'CO_PPE'\n",
    "],axis=1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After some manipulations and merging of Dataframes, we finally have the ideal Dataframe with all information we need in a more human friendly naming system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ano</th>\n",
       "      <th>Mes</th>\n",
       "      <th>Estado</th>\n",
       "      <th>Pais</th>\n",
       "      <th>Via</th>\n",
       "      <th>Produto</th>\n",
       "      <th>Kg</th>\n",
       "      <th>Amount(USD)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017</td>\n",
       "      <td>5</td>\n",
       "      <td>SC</td>\n",
       "      <td>BolÃ­via</td>\n",
       "      <td>RODOVIARIA</td>\n",
       "      <td>CombinaÃ§Ãµes de refrigeradores e congeladores (...</td>\n",
       "      <td>61327</td>\n",
       "      <td>312310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017</td>\n",
       "      <td>5</td>\n",
       "      <td>PR</td>\n",
       "      <td>BolÃ­via</td>\n",
       "      <td>RODOVIARIA</td>\n",
       "      <td>CombinaÃ§Ãµes de refrigeradores e congeladores (...</td>\n",
       "      <td>1092</td>\n",
       "      <td>3570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "      <td>SC</td>\n",
       "      <td>BolÃ­via</td>\n",
       "      <td>RODOVIARIA</td>\n",
       "      <td>CombinaÃ§Ãµes de refrigeradores e congeladores (...</td>\n",
       "      <td>58772</td>\n",
       "      <td>281605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017</td>\n",
       "      <td>8</td>\n",
       "      <td>SC</td>\n",
       "      <td>BolÃ­via</td>\n",
       "      <td>RODOVIARIA</td>\n",
       "      <td>CombinaÃ§Ãµes de refrigeradores e congeladores (...</td>\n",
       "      <td>95000</td>\n",
       "      <td>491717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017</td>\n",
       "      <td>5</td>\n",
       "      <td>MG</td>\n",
       "      <td>BolÃ­via</td>\n",
       "      <td>RODOVIARIA</td>\n",
       "      <td>CombinaÃ§Ãµes de refrigeradores e congeladores (...</td>\n",
       "      <td>2970</td>\n",
       "      <td>16919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2017</td>\n",
       "      <td>8</td>\n",
       "      <td>PR</td>\n",
       "      <td>BolÃ­via</td>\n",
       "      <td>RODOVIARIA</td>\n",
       "      <td>CombinaÃ§Ãµes de refrigeradores e congeladores (...</td>\n",
       "      <td>40324</td>\n",
       "      <td>228961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>PR</td>\n",
       "      <td>BolÃ­via</td>\n",
       "      <td>RODOVIARIA</td>\n",
       "      <td>CombinaÃ§Ãµes de refrigeradores e congeladores (...</td>\n",
       "      <td>20213</td>\n",
       "      <td>66990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>PR</td>\n",
       "      <td>BolÃ­via</td>\n",
       "      <td>RODOVIARIA</td>\n",
       "      <td>CombinaÃ§Ãµes de refrigeradores e congeladores (...</td>\n",
       "      <td>21078</td>\n",
       "      <td>75652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2017</td>\n",
       "      <td>10</td>\n",
       "      <td>SC</td>\n",
       "      <td>BolÃ­via</td>\n",
       "      <td>RODOVIARIA</td>\n",
       "      <td>CombinaÃ§Ãµes de refrigeradores e congeladores (...</td>\n",
       "      <td>144439</td>\n",
       "      <td>662794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2017</td>\n",
       "      <td>10</td>\n",
       "      <td>MG</td>\n",
       "      <td>BolÃ­via</td>\n",
       "      <td>RODOVIARIA</td>\n",
       "      <td>CombinaÃ§Ãµes de refrigeradores e congeladores (...</td>\n",
       "      <td>7138</td>\n",
       "      <td>42485</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Ano  Mes Estado     Pais         Via  \\\n",
       "0  2017    5     SC  BolÃ­via  RODOVIARIA   \n",
       "1  2017    5     PR  BolÃ­via  RODOVIARIA   \n",
       "2  2017    4     SC  BolÃ­via  RODOVIARIA   \n",
       "3  2017    8     SC  BolÃ­via  RODOVIARIA   \n",
       "4  2017    5     MG  BolÃ­via  RODOVIARIA   \n",
       "5  2017    8     PR  BolÃ­via  RODOVIARIA   \n",
       "6  2017    3     PR  BolÃ­via  RODOVIARIA   \n",
       "7  2017    2     PR  BolÃ­via  RODOVIARIA   \n",
       "8  2017   10     SC  BolÃ­via  RODOVIARIA   \n",
       "9  2017   10     MG  BolÃ­via  RODOVIARIA   \n",
       "\n",
       "                                             Produto      Kg  Amount(USD)  \n",
       "0  CombinaÃ§Ãµes de refrigeradores e congeladores (...   61327       312310  \n",
       "1  CombinaÃ§Ãµes de refrigeradores e congeladores (...    1092         3570  \n",
       "2  CombinaÃ§Ãµes de refrigeradores e congeladores (...   58772       281605  \n",
       "3  CombinaÃ§Ãµes de refrigeradores e congeladores (...   95000       491717  \n",
       "4  CombinaÃ§Ãµes de refrigeradores e congeladores (...    2970        16919  \n",
       "5  CombinaÃ§Ãµes de refrigeradores e congeladores (...   40324       228961  \n",
       "6  CombinaÃ§Ãµes de refrigeradores e congeladores (...   20213        66990  \n",
       "7  CombinaÃ§Ãµes de refrigeradores e congeladores (...   21078        75652  \n",
       "8  CombinaÃ§Ãµes de refrigeradores e congeladores (...  144439       662794  \n",
       "9  CombinaÃ§Ãµes de refrigeradores e congeladores (...    7138        42485  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_df.rename(\n",
    "    columns={\n",
    "        \"NO_VIA\":\"Via\",\n",
    "        \"NO_PAIS\":\"Pais\",\n",
    "        \"NO_NCM_POR\":\"Produto\"\n",
    "    },inplace=True)\n",
    "column_order = ['Ano','Mes','Estado','Pais','Via','Produto','Kg','Amount(USD)']\n",
    "exp_df = exp_df[column_order]\n",
    "exp_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next thing is to check for NAs, but there should not be many because all our merging was done using inner joins (we discarded information that was missing in either tables)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ano            0\n",
       "Mes            0\n",
       "Estado         0\n",
       "Pais           0\n",
       "Via            0\n",
       "Produto        0\n",
       "Kg             0\n",
       "Amount(USD)    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now check if States, Countries and Months are correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          SC\n",
       "1          PR\n",
       "4          MG\n",
       "14         SP\n",
       "271        MT\n",
       "295        ND\n",
       "686        AP\n",
       "798        AL\n",
       "800        ES\n",
       "814        RS\n",
       "815        MS\n",
       "907        RJ\n",
       "1308       PE\n",
       "2161       BA\n",
       "3213       CE\n",
       "3374       RE\n",
       "3852       RO\n",
       "4293       GO\n",
       "6535       RN\n",
       "7833       AC\n",
       "8134       RR\n",
       "8160       AM\n",
       "8389       PI\n",
       "14301      PA\n",
       "18735      DF\n",
       "23753      SE\n",
       "25935      PB\n",
       "33009      MA\n",
       "77219      TO\n",
       "153119     MN\n",
       "3566074    CB\n",
       "Name: Estado, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_df['Estado'].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                           BolÃ­via\n",
       "102                       Argentina\n",
       "113                        Paraguai\n",
       "176                           Chile\n",
       "184                         Uruguai\n",
       "                     ...           \n",
       "1002410      Cocos (Keeling), Ilhas\n",
       "1123306                    Toquelau\n",
       "1421174               Lebuan, Ilhas\n",
       "1652762                Bouvet, Ilha\n",
       "3390182    Marianas do Norte, Ilhas\n",
       "Name: Pais, Length: 252, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_df['Pais'].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "252"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_df['Pais'].drop_duplicates().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10     1\n",
       "7      2\n",
       "6      3\n",
       "2      4\n",
       "0      5\n",
       "16     6\n",
       "15     7\n",
       "3      8\n",
       "11     9\n",
       "8     10\n",
       "12    11\n",
       "17    12\n",
       "Name: Mes, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_df['Mes'].drop_duplicates().sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems we will have to remove 2 States that do not exist (MN and CB), the rest seems all right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_df = exp_df[(exp_df['Estado'] != 'MN')]\n",
    "exp_df = exp_df[exp_df['Estado'] != 'CB']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Analysing Exports\n",
    "\n",
    "Next step in our analysis is to answer the first question: list the top 3 exports by estate in 2017, 2018 and 2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ano</th>\n",
       "      <th>Estado</th>\n",
       "      <th>Produto</th>\n",
       "      <th>Amount(USD)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>115097</th>\n",
       "      <td>2019</td>\n",
       "      <td>TO</td>\n",
       "      <td>Soja, mesmo triturada, exceto para semeadura</td>\n",
       "      <td>772631871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115034</th>\n",
       "      <td>2019</td>\n",
       "      <td>TO</td>\n",
       "      <td>Carnes desossadas de bovino, congeladas</td>\n",
       "      <td>155101002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115044</th>\n",
       "      <td>2019</td>\n",
       "      <td>TO</td>\n",
       "      <td>Milho em grÃ£o, exceto para semeadura</td>\n",
       "      <td>78543244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74860</th>\n",
       "      <td>2018</td>\n",
       "      <td>TO</td>\n",
       "      <td>Soja, mesmo triturada, exceto para semeadura</td>\n",
       "      <td>995302750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74817</th>\n",
       "      <td>2018</td>\n",
       "      <td>TO</td>\n",
       "      <td>Carnes desossadas de bovino, congeladas</td>\n",
       "      <td>88538892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74818</th>\n",
       "      <td>2018</td>\n",
       "      <td>TO</td>\n",
       "      <td>Carnes desossadas de bovino, frescas ou refrig...</td>\n",
       "      <td>25932145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35026</th>\n",
       "      <td>2017</td>\n",
       "      <td>TO</td>\n",
       "      <td>Soja, mesmo triturada, exceto para semeadura</td>\n",
       "      <td>755967278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34977</th>\n",
       "      <td>2017</td>\n",
       "      <td>TO</td>\n",
       "      <td>Carnes desossadas de bovino, congeladas</td>\n",
       "      <td>78877967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34988</th>\n",
       "      <td>2017</td>\n",
       "      <td>TO</td>\n",
       "      <td>Milho em grÃ£o, exceto para semeadura</td>\n",
       "      <td>53312114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115001</th>\n",
       "      <td>2019</td>\n",
       "      <td>SP</td>\n",
       "      <td>Ãleos brutos de petrÃ³leo</td>\n",
       "      <td>3830462450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Ano Estado                                            Produto  \\\n",
       "115097  2019     TO       Soja, mesmo triturada, exceto para semeadura   \n",
       "115034  2019     TO            Carnes desossadas de bovino, congeladas   \n",
       "115044  2019     TO               Milho em grÃ£o, exceto para semeadura   \n",
       "74860   2018     TO       Soja, mesmo triturada, exceto para semeadura   \n",
       "74817   2018     TO            Carnes desossadas de bovino, congeladas   \n",
       "74818   2018     TO  Carnes desossadas de bovino, frescas ou refrig...   \n",
       "35026   2017     TO       Soja, mesmo triturada, exceto para semeadura   \n",
       "34977   2017     TO            Carnes desossadas de bovino, congeladas   \n",
       "34988   2017     TO               Milho em grÃ£o, exceto para semeadura   \n",
       "115001  2019     SP                           Ãleos brutos de petrÃ³leo   \n",
       "\n",
       "        Amount(USD)  \n",
       "115097    772631871  \n",
       "115034    155101002  \n",
       "115044     78543244  \n",
       "74860     995302750  \n",
       "74817      88538892  \n",
       "74818      25932145  \n",
       "35026     755967278  \n",
       "34977      78877967  \n",
       "34988      53312114  \n",
       "115001   3830462450  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_grouped = exp_df.groupby(['Ano','Estado','Produto'], as_index=False)['Amount(USD)'].sum()\n",
    "exp_grouped = exp_grouped.sort_values(by='Amount(USD)',ascending=False)\n",
    "exp_grouped = exp_grouped.groupby(['Ano','Estado']).head(3)\n",
    "exp_grouped = exp_grouped.sort_values(by=['Estado','Ano'],ascending=False)\n",
    "exp_grouped.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 26 States in Brazil, now we just have to find out how many different products we have to think about the best representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_grouped['Produto'].drop_duplicates().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115097         Soja, mesmo triturada, exceto para semeadura\n",
       "115034              Carnes desossadas de bovino, congeladas\n",
       "115044                 Milho em grÃ£o, exceto para semeadura\n",
       "74818     Carnes desossadas de bovino, frescas ou refrig...\n",
       "115001                             Ãleos brutos de petrÃ³leo\n",
       "                                ...                        \n",
       "35345     Outros aparelhos para filtrar ou depurar lÃ­quidos\n",
       "74954     Outras madeiras compensadas, constituÃ­das excl...\n",
       "74891           Castanha-do-parÃ¡, fresca ou seca, com casca\n",
       "74957     Outras miudezas comestÃ­veis de bovino, congeladas\n",
       "39        Outras madeiras de nÃ£o conÃ­feras perfilada (co...\n",
       "Name: Produto, Length: 64, dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_grouped['Produto'].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The names are hard to understand and there are many similar products in different categories. For this reason, we will rename them and merge when necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ano</th>\n",
       "      <th>Estado</th>\n",
       "      <th>Produto</th>\n",
       "      <th>Amount(USD)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019</td>\n",
       "      <td>TO</td>\n",
       "      <td>Soja</td>\n",
       "      <td>772631871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019</td>\n",
       "      <td>TO</td>\n",
       "      <td>Carne Bovina</td>\n",
       "      <td>155101002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019</td>\n",
       "      <td>TO</td>\n",
       "      <td>Milho</td>\n",
       "      <td>78543244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018</td>\n",
       "      <td>TO</td>\n",
       "      <td>Soja</td>\n",
       "      <td>995302750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018</td>\n",
       "      <td>TO</td>\n",
       "      <td>Carne Bovina</td>\n",
       "      <td>88538892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018</td>\n",
       "      <td>TO</td>\n",
       "      <td>Carne Bovina</td>\n",
       "      <td>25932145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2017</td>\n",
       "      <td>TO</td>\n",
       "      <td>Soja</td>\n",
       "      <td>755967278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2017</td>\n",
       "      <td>TO</td>\n",
       "      <td>Carne Bovina</td>\n",
       "      <td>78877967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2017</td>\n",
       "      <td>TO</td>\n",
       "      <td>Milho</td>\n",
       "      <td>53312114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2019</td>\n",
       "      <td>SP</td>\n",
       "      <td>PetrÃ³leo</td>\n",
       "      <td>3830462450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Ano Estado       Produto  Amount(USD)\n",
       "0  2019     TO          Soja    772631871\n",
       "1  2019     TO  Carne Bovina    155101002\n",
       "2  2019     TO         Milho     78543244\n",
       "3  2018     TO          Soja    995302750\n",
       "4  2018     TO  Carne Bovina     88538892\n",
       "5  2018     TO  Carne Bovina     25932145\n",
       "6  2017     TO          Soja    755967278\n",
       "7  2017     TO  Carne Bovina     78877967\n",
       "8  2017     TO         Milho     53312114\n",
       "9  2019     SP      PetrÃ³leo   3830462450"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_name_dict():\n",
    "    name_dict = {}\n",
    "    name_dict['madeiras'] = \"Madeira\"\n",
    "    name_dict['petrÃ³leo'] = \"PetrÃ³leo\"\n",
    "    name_dict['Milho'] = \"Milho\"\n",
    "    name_dict['Soja'] = \"Soja\"\n",
    "    name_dict['bovino'] = \"Carne Bovina\"\n",
    "    name_dict['aÃ§Ãºcares'] = \"AÃ§Ãºcar\"\n",
    "    name_dict['aviÃµes'] = \"AviÃµes\"\n",
    "    name_dict['Suco (sumo) de laranja'] = \"Suco de Laranja\"\n",
    "    name_dict['calÃ§ados'] = \"CalÃ§ados\"\n",
    "    name_dict['CalÃ§ados'] = \"CalÃ§ados\"\n",
    "    name_dict['galos/galinhas'] = \"Frango\"\n",
    "    name_dict['Tabaco'] = \"Tabaco\"\n",
    "    name_dict['Plataforma de perfuraÃ§Ã£o'] = \"MaquinÃ¡rio\"\n",
    "    name_dict['Barcos'] = \"Barcos\"\n",
    "    name_dict['Plataformas de perfuraÃ§Ã£o'] = \"Barcos\"\n",
    "    name_dict['suÃ­no'] = \"SuÃ­nos\"\n",
    "    name_dict['AutomÃ³veis'] = \"AutomÃ³veis\"\n",
    "    name_dict['Motocicletas'] = \"AutomÃ³veis\"\n",
    "    name_dict['Ouro'] = \"Ouro\"\n",
    "    name_dict['Arroz'] = \"Arroz\"\n",
    "    name_dict['madeira'] = \"Madeira\"\n",
    "    name_dict['Castanha'] = \"Castanha\"\n",
    "    name_dict['algodÃ£o'] = \"AlgodÃ£o\"\n",
    "    name_dict['AlgodÃ£o'] = \"AlgodÃ£o\"\n",
    "    name_dict['turborreatores'] = \"MaquinÃ¡rio\"\n",
    "    name_dict['Turborreatores'] = \"MaquinÃ¡rio\"\n",
    "    name_dict['aparelhos para filtrar'] = \"MaquinÃ¡rio\"\n",
    "    name_dict['mÃ¡quinas automÃ¡ticas'] = \"MaquinÃ¡rio\"\n",
    "    name_dict['motores'] = \"MaquinÃ¡rio\"\n",
    "    name_dict['ferro'] = \"Ferro\"\n",
    "    name_dict['Ferro'] = \"Ferro\"\n",
    "    name_dict['AviÃµes'] = \"AviÃµes\"\n",
    "    name_dict['madeiras'] = \"Madeira\"\n",
    "    name_dict['Madeira'] = \"Madeira\"\n",
    "    name_dict['tereftalato'] = \"PetrÃ³leo\"\n",
    "    name_dict['cobre'] = \"Cobre\"\n",
    "    name_dict['oil'] = \"PetrÃ³leo\"\n",
    "    name_dict['diesel'] = \"PetrÃ³leo\"\n",
    "    name_dict['mÃ¡quinas de medida'] = \"MaquinÃ¡rio\"\n",
    "    name_dict['cloreto de vinila'] = \"PetrÃ³leo\"\n",
    "    name_dict['Querosenes'] = \"PetrÃ³leo\"\n",
    "    name_dict['BulhÃ£o dourado'] = \"Ouro\"\n",
    "    name_dict['barbear'] = \"Aparelho barbear\"\n",
    "    name_dict['soja'] = \"Soja\"\n",
    "    name_dict['CafÃ©'] = \"CafÃ©\"\n",
    "    name_dict['Alumina'] = \"Aluminio\"\n",
    "    name_dict['titÃ¢nio'] = \"Titanio\"\n",
    "    name_dict['Ladrilhos'] = \"Material ConstruÃ§Ã£o\"\n",
    "    name_dict['elaboraÃ§Ã£o de bebidas'] = \"Bebidas\"\n",
    "    name_dict['Consumo de bordo'] = \"Consumo de bordo\"\n",
    "    return name_dict\n",
    "\n",
    "def get_category(line, name_dict):\n",
    "    for keyword in name_dict.keys():\n",
    "        if keyword in line:\n",
    "            return name_dict[keyword]\n",
    "    return line\n",
    "\n",
    "name_dict = get_name_dict()\n",
    "exp_grouped['Produto'] = exp_grouped['Produto'].apply(lambda x: get_category(x,name_dict))\n",
    "exp_grouped.reset_index(inplace=True, drop=True)\n",
    "exp_grouped.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#ax = sns.FacetGrid(exp_grouped, hue=\"Ano\", col=\"Estado\", sharey=False, palette=\"pastel\", sharex=False)\n",
    "#ax = ax.map(plt.bar, \"Produto\",\"Amount(USD)\")\n",
    "#ax = sns.barplot(x=\"Amount(USD)\", y=\"Ano\",data=exp_grouped[exp_grouped['Estado']=='SP'], hue=\"Produto\", orient=\"h\")\n",
    "\n",
    "ax = sns.catplot(\n",
    "    x=\"Amount(USD)\", \n",
    "    y=\"Ano\", \n",
    "    col=\"Estado\", \n",
    "    hue=\"Produto\",\n",
    "    data=exp_grouped,\n",
    "    kind=\"bar\", \n",
    "    palette=\"pastel\", \n",
    "    sharey=False,\n",
    "    sharex=False,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a rate of around 1:1 of product to state. This leaves us some "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_grouped = exp_df[exp_df['Ano']==2019].groupby(['Ano','Mes','Estado','Produto'], as_index=False)['Amount(USD)'].sum()\n",
    "exp_grouped = exp_grouped.sort_values(by='Amount(USD)',ascending=False)\n",
    "exp_grouped = exp_grouped.groupby(['Ano','Mes','Estado']).head(3)\n",
    "exp_grouped = exp_grouped.sort_values(by=['Estado','Mes','Ano'],ascending=False)\n",
    "exp_grouped.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_grouped['Produto'].drop_duplicates().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_grouped = exp_df[exp_df['Ano']==2019].groupby(['Ano','Estado'], as_index=False)['Amount(USD)'].sum()\n",
    "exp_grouped.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_sum = exp_grouped['Amount(USD)'].sum()\n",
    "print(total_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_grouped['percentage'] = exp_grouped.apply(lambda x: (x['Amount(USD)'] / total_sum) * 100, axis=1)\n",
    "exp_grouped = exp_grouped.sort_values(by='percentage',ascending=False)\n",
    "exp_grouped.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 10))\n",
    "ax = sns.barplot(x=\"percentage\", y=\"Estado\",data=exp_grouped)\n",
    "ax.set_title(\"Percentage of Exports for 2019\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
