{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and Export Data for Santa Catarina\n",
    "\n",
    "## Contents\n",
    "\n",
    "## Part 1: Data Wrangling\n",
    "\n",
    "First step to address our analysis will be to download the files, unzip them, clean them and finally organize the best way possible. I have decided to store the link to the government website and download it as we execute the notebook instead of uploading the file as Git LFS because those file locations **should not** change at all. Considering we are betting on the Brazilian government efficiency, we will store the MD5 of the used files \"just in case\" they ever change for any reason. One faster way to do this is simply download the zip files yourself and put them in the data folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import requests\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os\n",
    "import asyncio\n",
    "import hashlib\n",
    "import base64\n",
    "\n",
    "EXP_MD5 = \"\"\n",
    "IMP_MD5 = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download files (have patience young padawan...)\n",
    "async def download_to_data_folder(file_url:str)->str:\n",
    "    local_filename = 'data/'+file_url.split('/')[-1]\n",
    "    with requests.get(file_url, stream=True) as r:\n",
    "        r.raise_for_status()\n",
    "        with open(local_filename, 'wb') as f:\n",
    "            for chunk in r.iter_content(chunk_size=131072): \n",
    "                if chunk: # filter out keep-alive new chunks\n",
    "                    f.write(chunk)\n",
    "    return local_filename\n",
    "\n",
    "async def download_all_files()->list:\n",
    "    request_list = []\n",
    "    request_list.append(download_to_data_folder('http://www.mdic.gov.br/balanca/bd/comexstat-bd/ncm/EXP_COMPLETA.zip'))\n",
    "    request_list.append(download_to_data_folder('http://www.mdic.gov.br/balanca/bd/comexstat-bd/ncm/IMP_COMPLETA.zip'))\n",
    "    return asyncio.gather(*request_list)\n",
    "\n",
    "if not os.listdir('data/'):\n",
    "    file_list = await download_all_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'qQlAf4t9CVrpQ9h+fMMqfw=='\n"
     ]
    }
   ],
   "source": [
    "#check MD5\n",
    "for file in os.listdir('data/'):\n",
    "    if file.startswith('EXP_'):\n",
    "        file_hash = hashlib.md5()\n",
    "        with open('data/'+file,'rb') as f:\n",
    "            for chunk in iter(lambda: f.read(2**20*file_hash.block_size), b''):\n",
    "                file_hash.update(chunk)\n",
    "        print(base64.b64encode(file_hash.digest()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unzip files\n",
    "for file in os.listdir('data/'):\n",
    "    print(file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
